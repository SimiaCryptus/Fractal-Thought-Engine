# The Evaporating Substrate: Human Value in the Age of Automated Cognition

## I. The Migrating Basis of Power

Every civilizational order rests on an implicit answer to the question: *what makes humans valuable?* Not morally — that answer is easy and cheap — but *functionally*, within the power structures that actually govern resource allocation, status, and survival. The substrate of that functional value has migrated three times in the modern era, and each migration has rendered a different dimension of human capability obsolete.

**Regime 1: Animal Strength → Industrial Mass.** For most of recorded history, human value in the context of power was grounded in the body. Armies were collections of primate strength — men who could march, swing, hold a line. Political authority flowed from the capacity to organize and project physical violence. The sovereign who could field more bodies, and keep them fed and moving, dominated.

**Regime 2: Industrial Mass → Cognitive Elites.** The twentieth century — specifically the period from roughly 1940 to 2020 — shifted the locus of civilizational power from mass to mind. The atomic bomb was not built by an army. It was built by a handful of physicists. The information revolution was not driven by factory labor. It was driven by mathematicians, engineers, and programmers. Human value, in the functional sense that matters to power, migrated from muscle to cognition.

**Regime 3: Cognitive Elites → Automated Cognition.** We are now inside the third migration. The scarcity of intelligence — the thing that made the cognitive elite valuable — is collapsing. Large-scale AI systems can now perform, and in many domains exceed, the cognitive labor that justified the post-WWII social contract. The substrate of human worth is evaporating, and nothing has yet replaced it.

Each of these transitions was accompanied by massive violence, institutional collapse, and the wholesale rewriting of who counts as a person. There is no reason to believe the third will be different. There are several reasons to believe it will be worse.

---

## II. The Napoleonic/Civil War Hinge

The first regime transition — from primate-scale dominance to industrial-scale warfare — played out across the long nineteenth century, and its lessons are still underappreciated.

Napoleon's campaigns were, in one sense, the apotheosis of the old model: a single charismatic commander projecting power through the massed bodies of citizen-soldiers. But they were also the beginning of its end. The logistics of the Grande Armée — the supply chains, the road networks, the administrative apparatus required to move 600,000 men into Russia — were already industrial problems wearing pre-industrial clothes. Napoleon didn't lose to a better general. He lost to distance, weather, and the caloric requirements of half a million mammals.

The American Civil War made the lesson explicit. The Confederacy fought, in many respects, a Napoleonic war: aristocratic officer corps, cavalry charges, the romance of individual valor. The Union fought an industrial war: railroads, telegraphs, factory-produced rifles, and the grim arithmetic of attrition. Grant's strategy was not brilliant in the classical sense. It was *systematic*. He understood that the North could replace its losses and the South could not. He turned the war into a resource-consumption problem and solved it with logistics.

What followed was not peace but transformation. The Gilded Age was the political economy of the new regime: human value now resided not in martial prowess but in the capacity to operate, manage, and profit from industrial systems. The old martial aristocracies didn't vanish — they adapted, or were replaced by industrial magnates who wielded a different kind of power. The humans who couldn't adapt — subsistence farmers, artisans, the formerly enslaved — were not gently retrained. They were crushed, exploited, or ignored.

The communist revolutions of the twentieth century were, in this framing, a delayed immune response to the first regime transition. Marx diagnosed the problem with extraordinary precision: industrial capitalism had made human labor a commodity, and commodities are subject to price competition. The workers whose bodies had once been the irreducible unit of military and economic power were now interchangeable components in a machine that didn't care about them. The revolutionary answer — seize the means of production, restore human dignity through collective ownership — was a *political* solution to what was fundamentally a *substrate* problem. It addressed who controlled the machines, not the deeper issue that machines had devalued the human body as a source of power.

This is the pattern. The substrate of value migrates. The humans left standing on the old substrate experience it as an existential crisis — not merely economic, but *ontological*. And the political responses, however radical, tend to fight the last war.

---

## III. The WWII Reprieve

The Second World War created a new myth, and for eighty years that myth held.

The myth was this: *human value equals intelligence*. The war was won — or at least, its decisive asymmetries were created — by a tiny cohort of extraordinary minds. Alan Turing broke Enigma and, in doing so, arguably shortened the war by years. John von Neumann's mathematical contributions spanned ballistics, shock waves, and the foundational architecture of the digital computer. Robert Oppenheimer led the Manhattan Project, converting theoretical physics into the most consequential weapon in history. Claude Shannon formalized information theory, laying the groundwork for every communication system that followed.

These were the "wizards" — and their existence created a new social contract. If intelligence was the substrate of civilizational power, then societies needed to cultivate, educate, and reward intelligence. The postwar order was built on this logic. The GI Bill, the expansion of universities, the creation of national research laboratories, the space race, the semiconductor industry, Silicon Valley — all of it rested on the premise that smart humans were the scarce resource that determined national power.

The Cold War locked this in with existential stakes. The United States and the Soviet Union competed not primarily through massed armies (though they maintained them) but through technological capability: nuclear weapons, satellites, computers, cryptography. The arms race was, at its core, a *talent* race. Both superpowers invested enormously in identifying, training, and deploying cognitive elites. Human intelligence was the strategic resource, and the entire institutional apparatus of the postwar world — from university tenure to defense contracting to immigration policy — was organized around capturing and leveraging it.

This created a genuine golden age for a certain kind of human. If you were smart, educated, and positioned within the right institutional frameworks, the postwar order valued you enormously. The knowledge economy wasn't just an economic phenomenon; it was a *moral* one. Intelligence became the basis of social worth, the justification for meritocratic hierarchies, the answer to the question of why some people deserved more than others.

But it was always a contingent arrangement, not a natural law. Intelligence was valued because it was *scarce relative to the demands of power*. The moment that scarcity collapsed, the entire edifice — economic, social, moral — would lose its foundation.

---

## IV. The Current Evaporation

That moment is now.

The development of large-scale AI systems has done to cognitive labor what the steam engine did to physical labor: not eliminated it entirely, but destroyed its scarcity value. A language model can draft legal briefs, write code, analyze medical images, compose music, summarize research, and generate strategic analyses. It does these things imperfectly — but it does them at near-zero marginal cost, at scale, without sleep, without benefits, without complaint.

The analogy that clarifies the situation is the horse. In 1900, the United States had approximately 21 million horses. They were essential to transportation, agriculture, industry, and warfare. The entire economy was organized around their capabilities. By 1960, the horse population had collapsed to roughly 3 million, and horses had become recreational luxuries. No one "solved" the horse unemployment problem. There was no retraining program, no equine universal basic income. Horses simply stopped being economically necessary, and their numbers adjusted accordingly.

The critical difference, of course, is that horses don't vote, don't riot, and don't build nuclear weapons. Humans do. But the economic logic is identical: when a cheaper substitute exists for the function you perform, your market value collapses regardless of your intrinsic qualities.

What makes the current transition uniquely dangerous is that it attacks the *last* substrate. When industrial machines replaced human muscle, humans could retreat to cognition — "we're not just bodies, we're *minds*." When AI replaces human cognition, there is no further retreat. The implicit promise of the Enlightenment — that human reason is the highest and most irreplaceable capacity in the universe — is being falsified in real time, not by philosophical argument but by engineering.

Simultaneously, the global economic system has reached a state of overintegration that amplifies every shock. Supply chains span continents. Financial markets are coupled in milliseconds. Labor markets are global. This means that the displacement effects of AI are not local or gradual — they propagate through the entire system at the speed of information. A breakthrough in automated coding doesn't just affect programmers in San Francisco; it reprices cognitive labor worldwide, instantaneously.

Late-stage capitalism, in this context, is not merely an economic arrangement but a *vulnerability*. The system is optimized for efficiency, not resilience. It has no slack, no buffers, no fallback positions. When the substrate of human value evaporates, the system has no mechanism for absorbing the displaced — because the system was never designed to value humans *as such*. It was designed to value human *functions*, and those functions are being automated.

Humans are becoming friction, not assets. Every human in a workflow is a source of latency, error, liability, and cost. The economic incentive is to remove them — not out of malice, but out of the same optimization logic that removed horses from transportation. The question is not whether this will happen but how fast, and what the humans do as it happens to them.

---

## V. Bifurcation Dynamics

The language of dynamical systems is not a metaphor here. It is the most precise framework available for understanding what is occurring.

In a dynamical system, variables operate on different timescales. *Fast variables* — daily routines, institutional procedures, social norms, market prices — adjust quickly to changing conditions. *Slow variables* — perceived human worth, economic inclusion, institutional legitimacy, shared meaning frameworks — change over decades or generations. The stability of any social order depends on the slow variables remaining within a range where the fast variables can find a workable equilibrium.

A *bifurcation* occurs when the slow variables drift beyond a critical threshold, and the old equilibrium ceases to exist. The fast variables don't gradually adjust — they undergo a qualitative phase transition, snapping to a new attractor that may bear little resemblance to the old one. This is not a smooth process. It is characterized by increasing oscillation, loss of resilience to perturbation, and eventual rapid reorganization.

The slow variables of the current global order have been drifting for decades:

**Perceived human worth** has been declining since the 1970s, as wages decoupled from productivity, as financialization rewarded capital over labor, and as the knowledge economy concentrated returns among a shrinking elite. AI accelerates this decline from a trend to a cliff.

**Economic inclusion** — the fraction of the population that participates meaningfully in the economy as producers, not just consumers — has been narrowing. The gig economy, the hollowing of the middle class, the rise of "bullshit jobs" (in David Graeber's formulation) are all symptoms of a system that needs fewer humans but hasn't yet acknowledged it.

**Institutional legitimacy** is in freefall across the developed world. Trust in government, media, science, and democratic processes has declined monotonically for decades. Institutions are increasingly perceived not as neutral arbiters but as captured instruments of elite interests. This perception is, in many cases, accurate.

**Meaning frameworks** — the shared stories that tell people why their lives matter, why suffering is bearable, why the future is worth investing in — are fragmenting. Religious participation is declining. National narratives are contested. The meritocratic promise ("work hard, get educated, succeed") is visibly failing for a growing majority. Nothing coherent has replaced these frameworks.

Each of these slow variables, individually, represents a serious problem. Together, they constitute a system approaching bifurcation. The fast variables — the norms, routines, and institutions that organize daily life — are increasingly unable to find stable configurations. This manifests as political polarization, institutional dysfunction, rising anxiety and despair, and the proliferation of conspiratorial and apocalyptic thinking. These are not causes; they are *symptoms* of a system losing its attractor.

The mathematical point is important: bifurcations are not reversible by small interventions. Once the slow variables cross the critical threshold, the old equilibrium doesn't just become difficult to maintain — it *ceases to exist as a mathematical object*. You cannot return to it by trying harder. You can only navigate toward a new attractor, and the set of available attractors may include configurations that are, from a human welfare perspective, catastrophic.

This is not melodrama. It is the standard analysis of any complex adaptive system undergoing a regime shift. The same mathematics describes ecosystem collapse, financial crises, and the fall of empires. The question is not whether a bifurcation is occurring but what the new attractor looks like — and whether humans have any agency in selecting among the possibilities.

---

## VI. The Violence Risk

History offers a consistent pattern for what happens when large populations lose their perceived basis of worth: *they become dangerous, and then they become victims*.

The sequence is well-documented across civilizations and centuries. **Loss of perceived worth** generates **status panic** — a visceral, often pre-rational terror that one's place in the social order is collapsing. Status panic generates **scapegoating** — the identification of an out-group responsible for the loss. Scapegoating generates **dehumanization** — the rhetorical and psychological process of recategorizing the out-group as less than human. Dehumanization generates **violence**, up to and including genocide.

This is not a slippery-slope argument. It is an empirical regularity. The Weimar Republic's economic humiliation preceded the Holocaust. The Rwandan Hutu's perceived subordination preceded the genocide of the Tutsi. The Ottoman Empire's decline preceded the Armenian genocide. In every case, the proximate trigger was economic or military, but the deeper driver was a crisis of *worth* — a population that could no longer locate its value within the existing order and resolved the cognitive dissonance through exterminatory violence.

The current moment is more dangerous than a labor crisis, more dangerous than a recession, more dangerous than a trade war — because it attacks the *existential story* of why humans matter. A person who loses their job can, in principle, find another. A person who loses their *category of usefulness* — who is told, implicitly or explicitly, that no human function they can perform is worth paying for — faces a crisis that no job retraining program can address.

The populations most at risk are not the poorest (who have long been excluded and have developed survival strategies) but the *formerly valued* — the middle classes of developed nations who built their identities around cognitive labor, professional status, and the meritocratic promise. These are the populations with the most to lose, the most access to political and military resources, and the most historically demonstrated capacity for organized violence when their status is threatened.

The scapegoating has already begun. It is visible in the rise of nativist movements, in the targeting of immigrants and minorities, in the conspiratorial narratives that attribute economic decline to shadowy elites or foreign enemies. These narratives are *functionally* correct — someone *is* responsible for the displacement — but they systematically misidentify the cause. The cause is not immigrants or elites or globalists. The cause is a substrate shift that no human agent controls. But substrate shifts are abstract and unsatisfying. Scapegoats are concrete and cathartic.

The risk is not that AI will *decide* to harm humans. The risk is that humans, stripped of their functional value and desperate for an explanation, will harm each other — and that the institutional safeguards designed to prevent this are themselves eroding.

---

## VII. States Fighting for Dominance Without Humans

The competition between nation-states has always been the engine of history's worst violence. What is new is that this competition is increasingly *mediated by systems that don't require human participation*.

Military power is migrating from human soldiers to autonomous systems — drones, cyber weapons, algorithmic targeting, AI-driven logistics. Economic power is migrating from human workers to automated supply chains, algorithmic trading, and AI-optimized production. Intelligence power is migrating from human analysts to machine learning systems that can process satellite imagery, intercept communications, and identify patterns at scales no human organization can match.

The implications are profound. Historically, states needed their populations — as soldiers, as workers, as taxpayers, as sources of innovation. This need created a *structural incentive* for states to invest in human welfare. Public education, healthcare, infrastructure, and social safety nets were not acts of charity; they were investments in the human capital that states required to compete. The democratic social contract — citizens provide labor and loyalty; the state provides security and opportunity — was grounded in mutual dependence.

As states become capable of projecting power without human labor, this mutual dependence dissolves. A state that can fight its wars with drones, run its economy with algorithms, and surveil its population with AI has *no structural need* for an educated, healthy, empowered citizenry. It needs a *compliant* citizenry, or better yet, a *small* citizenry — enough to maintain the systems, not enough to threaten them.

This is not speculation. It is the revealed logic of petrostates, which have long demonstrated what governance looks like when the state's revenue is independent of its population's productivity. Petrostates tend toward authoritarianism, rentier economics, and the treatment of citizens as liabilities rather than assets. The AI transition threatens to turn *every* state into a petrostate — not because of oil, but because the "resource" that generates power (automated cognition) is similarly independent of broad human participation.

The great power competition between the United States and China is already being fought primarily on the terrain of AI capability, semiconductor supply chains, and data infrastructure — not on the terrain of human welfare or democratic legitimacy. Both states are investing enormously in AI not because it will make their citizens' lives better (though that is the stated justification) but because it will make their *states* more powerful relative to rivals. The citizens are, increasingly, spectators to a contest that will determine their fate but does not require their contribution.

---

## VIII. The Collapse of Due Process and Institutional Safeguards

The theoretical response to every crisis outlined above is: *use the institutions*. Advocate. Organize. Vote. Litigate. Reform. This is the liberal democratic answer, and it assumes that the institutions are functional, accessible, and responsive.

They are not.

Even in the nations that consider themselves citadels of human rights and rule of law, the procedural protections that theoretically safeguard human dignity are being hollowed out. This erosion is not primarily the result of malice (though malice plays a role); it is the result of the same optimization logic that is displacing human labor. Institutions are being streamlined, automated, and captured — made more efficient at serving their *actual* constituencies (concentrated economic and political power) and less responsive to their *nominal* constituencies (citizens).

The judiciary is slow, expensive, and increasingly inaccessible to ordinary people. Regulatory agencies are captured by the industries they nominally regulate. Legislative bodies are gridlocked, gerrymandered, and responsive primarily to donor interests. The media ecosystem — the "fourth estate" that theoretically holds power accountable — has fragmented into algorithmically optimized outrage machines that generate heat but not light.

Democratic participation itself is being undermined — not by the crude methods of earlier authoritarians (stuffing ballot boxes, banning opposition parties) but by subtler mechanisms: voter suppression through administrative complexity, the flooding of the information environment with noise and disinformation, the gerrymandering of districts to predetermine outcomes, and the sheer *irrelevance* of electoral politics to the decisions that actually matter. When the consequential choices about AI deployment, labor displacement, and economic restructuring are made by corporate boards and technical teams operating outside any democratic framework, voting becomes a ritual rather than an instrument of power.

This creates a vicious cycle. As institutions become less responsive, citizens disengage. As citizens disengage, institutions become more captured. As institutions become more captured, the policy responses that might address the substrate crisis become less likely. The people who most need institutional protection are the least able to access it, and the institutions that most need reform are the least capable of reforming themselves.

The result is that the theoretical toolkit for managing the transition — regulation, redistribution, retraining, democratic deliberation — exists in a kind of Platonic realm, beautiful and inaccessible. The policies that could help are known. The political will to implement them is absent. The institutions that could generate that political will are broken. And the timeline is short.

---

## IX. What Is To Be Done?

Despite everything above, the situation is not *logically* hopeless. The bifurcation has not yet occurred. The slow variables are drifting, but they have not yet crossed every critical threshold. There are strategic levers that, if pulled with sufficient force and coordination, could steer the system toward a less catastrophic attractor. They deserve honest enumeration — and honest assessment.

**Narrative reframing.** The most urgent intervention is also the most abstract: changing the story humans tell about why they matter. If human value is grounded in *function* — in what humans can *do* — then the AI transition is an extinction-level event for human worth. If human value can be regrounded in something else — in consciousness, in relationship, in the sheer improbability and preciousness of subjective experience — then the transition, while still enormously disruptive, is survivable. This is not a trivial reframing. It requires displacing centuries of utilitarian and productivist thinking. But it is the only reframing that addresses the root cause rather than the symptoms.

**Economic redistribution.** If human labor is no longer the primary source of economic value, then the distribution of economic output can no longer be tied to labor. Universal basic income, sovereign wealth funds, public ownership of AI infrastructure, aggressive taxation of automated production — these are not radical proposals. They are the *minimum* necessary adjustments to an economy in which the labor theory of value has been empirically falsified. The technical designs exist. The political obstacles are enormous but not, in principle, insurmountable.

**Algorithmic governance.** The systems that are displacing human labor and mediating state power need to be subject to democratic oversight — not in the weak sense of "transparency reports" and "ethics boards," but in the strong sense of public control over deployment decisions, mandatory impact assessments, and enforceable constraints on autonomous systems. This requires a new institutional vocabulary: regulatory frameworks designed for systems that learn, adapt, and operate at speeds that exceed human comprehension. No such frameworks currently exist at scale.

**Institutional modernization.** The democratic institutions built for the industrial age need to be rebuilt for the AI age. This means not just reforming existing institutions but creating new ones: citizens' assemblies with real power, digital public infrastructure that is not controlled by private corporations, international governance bodies with jurisdiction over AI development and deployment. The current institutional landscape is not merely inadequate; it is *architecturally* wrong for the problems it faces.

**Local resilience.** At the community level, the most robust strategy is to build systems that can function independently of the global optimization machine: local food production, community energy systems, mutual aid networks, local currencies, and social structures that provide meaning and belonging outside the market economy. These are not solutions to the global problem, but they are *buffers* — they buy time and provide fallback positions when the global system fails.

---

## X. The Honest Assessment

Here is the part where intellectual honesty demands its price.

Every lever described above is real. Every one has been demonstrated at small scale. Every one could, in principle, be implemented. And the overwhelming likelihood is that none of them will be implemented at the speed and scale required.

The reason is not that humans are stupid or evil. The reason is that the levers require *coordination* — across nations, across classes, across ideological divides — and the same dynamics that are creating the crisis are also destroying the capacity for coordination. You cannot build new institutions when trust in institutions is collapsing. You cannot redistribute wealth when the political system is captured by wealth. You cannot reframe narratives when the information ecosystem is optimized for fragmentation. You cannot govern algorithms when the entities that build them are more powerful than the governments that would regulate them.

This is the trap. The crisis demands collective action, and the crisis destroys the preconditions for collective action. It is a dynamical system with a positive feedback loop driving it toward the bad attractor, and the interventions that could break the loop require the very capacities that the loop is degrading.

Humans are unlikely to do this the easy way.

The easy way would be: recognize the substrate shift early, implement redistributive and institutional reforms proactively, reground human value in something durable, and navigate the transition with minimal violence and maximal preservation of dignity. This would require a level of foresight, coordination, and self-sacrifice that human civilizations have almost never demonstrated.

The hard way — the way that history suggests is far more likely — involves the full sequence: displacement, denial, scapegoating, conflict, partial collapse, and then, eventually, the construction of new institutions from the wreckage. The question is how deep the collapse goes and how many people it kills.

This is not fatalism. It is pattern recognition. The Napoleonic transition killed millions before the industrial order stabilized. The WWII transition killed tens of millions before the cognitive order stabilized. The scale of violence tends to increase with the scale of the transition, and the current transition is the largest in human history — because it is the first to attack the *last* substrate of human functional value.

The task for those who see this clearly is not to prevent the bifurcation — that may be beyond anyone's power — but to *prepare for it*. To build the local resilience that can survive the transition. To preserve the knowledge and the moral frameworks that will be needed to construct whatever comes next. To maintain, against all evidence and all incentive, the conviction that human beings have value that is not contingent on their economic function — and to build communities that embody that conviction in practice, not just in rhetoric.

The substrate of power will continue to migrate. It always has. The question that matters — the only question that has ever mattered — is whether humans can construct a basis for their own worth that doesn't depend on being useful to the machine. If they can, the future is navigable. If they cannot, they will share the fate of the horse: not destroyed, but *irrelevant* — a living anachronism in a world that has moved on.

The answer is not yet determined. But the window for determining it is closing, and it is closing fast.